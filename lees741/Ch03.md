# Ch03. 저장소와 검색
> 데이터베이스가 데이터를 저장하는 방법과 데이터를 다시 찾는 방법을 설명한다.
## 데이터베이스를 강력하게 만드는 데이터 구조
* 많은 데이터베이스는 내부적으로 append-only 데이터 파일인 로그를 사용한다. (연속된 append-only 레코드)
* 매번 데이터를 찾을 때마다 전체 데이터베이스 파일을 처음부터 끝까지 스캔하는 것은 매우 비효율적 (`O(n)`)
  * 부가적인 메타데이터를 유지하는 색인 사용해 읽기 쿼리 속도 향상 가능
  * 그러나 쓰기 쿼리의 경우 단순히 파일에 레코드를 추가하는 것보다 색인을 유지하는 것이 비용이 더 크다.
  >💡 trade-off 고려해야 함!

### 해시 색인
> 키-값 데이터 색인을 해시 맵(해시 테이블)으로 구현
* 인메모리 해시 맵으로 디스크 상의 데이터를 색인
  * 단순히 키에 대한 값에 데이터 파일의 바이트 오프셋 매핑하는 것으로 색인 가능
  * 쓰기가 매우 많이 일어나지만, 고유 키의 개수가 많지 않은 경우 유용하다.
* 파일에 항상 추가(append-only)만 한다면 디스크 공간이 부족해지지는 않을까?
  * 세그먼트로 로그를 나눠 해결
  * 세그먼트가 특정 크기에 도달하면 쓰기를 멈추고 새로운 세그먼트 파일에 이후 쓰기 수행
  * 백그라운드 스레드에서 컴팩션 수행 (로그에서 중복된 키를 버리고 각 키의 최신 값만 유지)
* 제한 사항
  * 키의 개수가 너무 많으면 색인의 크기가 커져 메모리에 저장할 수가 없다.
  * 해시 테이블은 범위 질의에 효율적이지 않기 때문에 연속된 키를 조회할 때에도 해시 테이블에서 각 키를 모두 조회해야 한다.

### SS 테이블과 LSM 트리
> 키-값 데이터 색인을 키로 정렬된 세그먼트 파일로 구현

* 정렬된 문자열 테이블 (Sorted String Table)
  * 각 세그먼트 파일을 SS 테이블로 관리하고 병합정렬 알고리즘과 유사한 방식으로 컴팩션
* 메모리에 모든 키의 색인을 유지할 필요가 없다. (정렬되어 있기 때문에 키와 키 사이의 위치로 알 수 있다.)

#### SS 테이블 생성과 유지
* 쓰기 요청이 들어오면 인메모리 균형 트리(ex. 레드-블랙 트리)에 추가. 이를 멤테이블이라고도 한다.
* 멤테이블의 크기가 임곗값보다 커지면 SS 테이블 파일로 디스크에 기록
* 읽기 요청이 들어오면 우선 멤테이블에서 키를 찾음. 그 다음 디스크 상의 가장 최신 세그먼트, 두 번째 세그먼트 등 순서로 찾음.
* 주기적으로 백그라운드에서 세그먼트 파일을 합치고 덮어 쓰는 컴팩션 수행 
###### 만약 데이터베이스가 고장난다면?
* 디스크에 아직 기록되지 않은 멤테이블 내용은 손실된다.
* 이를 대비해 매 쓰기 요청을 즉시 디스크에 저장하는 로그가 필요하다. (정렬할 필요 없음)

#### SS 테이블에서 LSM 트리 만들기
* 정렬된 파일 병합과 컴팩션 원리를 기반으로 하는 저장소 엔진을 LSM 저장소 엔진이라고 한다.

#### 성능 최적화
* 존재하지 않는 키를 찾는 경우 멤테이블을 확인하고 이후 디스크에서 가장 오래된 세그먼트까지 확인을 해야한다.
  * 블룸 필터(키가 데이터베이스에 존재하지 않음을 알려주는 집합과 유사한 데이터 구조)를 이용해 최적화

> 💡 결론
 
* 백그라운드에서 연쇄적으로 SS 테이블을 지속적으로 병합하는 것이 핵심
* 데이터가 정렬된 순서로 저장돼 있기 때문에 범위 쿼리를 효율적으로 실행할 수 있음
* 또한, 디스크 쓰기가 순차적이기 때문에 높은 쓰기 처리량 보장 (특히, HDD에서)

### B 트리
> 데이터베이스를 고정 크기 블록이나 페이지로 나누고 트리의 노드 크기를 블록이나 페이지 크기에 맞춘 색인
* 디스크에 접근할 때는 블록이나 페이지 단위로 하기 때문에 좀 더 하드웨어와 밀접한 설계

#### 신뢰할 수 있는 B 트리 만들기
* 새로운 데이터를 쓸 때 LSM 트리와는 달리 파일에 추가하는 방식이 아닌 디스크 상의 페이지에 덮어쓰는 방식
* 만약, 덮어쓰기 도중에 데이터베이스가 고장 난다면 인덱스가 훼손된다. (ex. 고아 페이지)
* 이를 대비해 디스크 상에 쓰기 전 로그(write-ahead log, WAL)를 추가해 복원에 사용

#### LSM 트리의 장점
* B 트리에 비해 쓰기 증폭이 낮고 여러 페이지를 덮어쓰는 것이 아니라 순차적으로 컴팩션된 SS 테이블을 쓰기 때문에 쓰기 처리량이 더 높다.
  * SSD는 블록 덮어쓰기 횟수가 제한되기 때문에 쓰기 증폭이 중요하고 HDD는 순차 쓰기가 임의 쓰기보다 훨씬 빠르기 때문에 쓰기 패턴이 중요하다.
* B 트리보다 디스크에 더 적은 파일을 생성한다. (컴팩션)

#### LSM 트리의 단점
* 컴팩션 과정이 진행 중인 읽기와 쓰기의 성능에 영향을 준다.
  * 디스크의 쓰기 대역폭은 유한하기 때문에 백그라운드 컴팩션 스레드가 대역폭을 공유해야 한다.
* 컴팩션이 유입되는 쓰기 요청 속도를 따라가지 못하면 세그먼트 수는 디스크 공간이 부족할 때까지 증가한다.
  * 확인해야 하는 세그먼트 파일이 늘어나 읽기 요청도 느려진다. (악순환)
  * 심지어 보통의 LSM 저장소 엔진은 컴팩션이 유입 속도를 따라가지 못해도 유입 쓰기 속도를 조절하지 않기 때문에 이러한 상황을 감지하기 위한 모니터링이 필요하다.

### 기타 색인 구조
#### 모든 것을 메모리에 보관
> 데이터셋 전체를 메모리에 보관하는 인메모리 데이터베이스
* 멤캐시드 같은 일부 인메모리 키-값 저장소는 장비가 재시작되면 데이터 손실을 허용하는 캐시 용도로만 사용
* 다른 인메모리 데이터베이스는 지속성을 목표로 한다. (메모리는 재시작되면 다 날라가는데 어떻게?)
  * 배터리 전원 공급 RAM과 같은 특수 하드웨어를 쓰거나
  * 디스크에 변경 사항의 로그를 기록하거나 주기적으로 스냅샷 기록, 다른 장비에 인메모리 상태 복제
* 디스크에 기록하는데 인메모리 데이터베이스라고 할 수 있나?
  * 디스크는 오로지 지속성을 위한 전용 로그로 사용되고 읽기는 전적으로 메모리에서 제공되기 때문
* 사실 디스크 기반 데이터베이스 엔진도 OS가 최근에 사용한 디스크 블록을 메모리에 캐시하는데?
* 그럼에도 인메모리 데이터베이스는 디스크 기반 색인으로 구현하기 어려운 데이터 모델 제공
  * ex. 레디스: 우선순위 큐와 셋 같은 다양한 데이터 구조 제공

## 트랜잭션 처리나 분석?
> 트랜잭션은 논리 단위 형태로서 읽기와 쓰기 그룹을 나타낸다.

| 특성       | 트랜잭션 처리 시스템(OLTP)            | 분석 시스템(OLAP)        |
|----------|------------------------------|---------------------|
| 주요 읽기 패턴 | 질의당 적은 수의 레코드, 키 기준으로 가져옴    | 많은 레코드에 대한 집계       |
| 주요 쓰기 패턴 | 임의 접근, 사용자 입력을 낮은 지연 시간으로 기록 | 대규모 불러오기 또는 이벤트 스트림 |
| 주요 사용처   | 웹 애플리케이션을 통한 최종 유저           | 의사결정 지원을 위한 내부 분석가  |
| 데이터 표현   | 데이터의 최신 상태                   | 시간이 지나며 일어난 이벤트 이력  |
| 데이터셋 크기  | GB ~ TB                      | TB ~ PB             |

* 처음에는 트랜잭션 처리와 분석 질의를 위해 동일한 DB를 사용했지만 이후 개별 DB에 분석을 수행하는 경향을 보였다.
  * 이 개별 데이터베이스를 데이터 웨어하우스라고 불렀다.

### 데이터 웨어하우징
* OLTP 시스템은 비즈니스에 대단히 중요하기 때문에 보통 높은 가용성과 낮은 지연 시간을 가진다.
그렇기 때문에 DBA는 비즈니스 분석가가 OLTP DB에 (비용이 비싼) 분석 쿼리를 실행하는 것을 꺼려한다.
따라서 OLTP에 영향을 주지 않고 마음껏 분석 쿼리를 실행할 수 있는 개별 DB인 데이터 웨어하우스를 사용한다.
  * 데이터 웨어하우스는 OLTP 데이터의 읽기 전용 복사본
  * ETL(Extract-Transform-Load): 데이터를 주기적으로 추출하고 분석 친화적인 스키마로 변환한 뒤 적재하는 과정

## 칼럼 지향 저장소
> 일반적인 데이터 웨어하우스 쿼리는 한 번에 4개 또는 5개 칼럼만 접근한다.
* 수많은 로우를 모두 메모리에 적재한 다음 구문을 해석해 필요한 조건을 충족하지 않은 로우를 필터링하는 경우가 대부분
* 모든 값을 하나의 로우에 함께 저장하지 않는 대신 각 칼럼별로 모든 값을 함께 저장
  * 각 칼럼 파일에 포함된 로우가 모두 같은 순서인 점에 의존
* 데이터 웨어하우스에서는 디스크 대역폭이 병목인 경우가 많기 때문에 칼럼 지향 저장소로 데이터를 매우 작게 부호화하는 일이 중요하다.